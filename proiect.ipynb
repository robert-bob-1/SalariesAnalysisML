{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"end_to_end_project\"\n",
    "\n",
    "input_file = \"ds_salaries.csv\"\n",
    "data = pd.read_csv(input_file, header = 0)\n",
    "data.head()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a scatter plot of YearsExperience vs Salary\n",
    "plt.scatter(data['work_year'], data['salary'])\n",
    "\n",
    "# Add labels and title to the plot\n",
    "plt.xticks(range(int(min(data['work_year'])), int(max(data['work_year']))+1, 1))\n",
    "\n",
    "plt.xlabel('work_year')\n",
    "plt.ylabel('salary')\n",
    "plt.title('salary vs work_year')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "data.hist(bins=50, figsize=(20,15))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up the set\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if there are any missing values in our columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for missing values\n",
    "\n",
    "columns_with_miss = data.isna().sum()\n",
    "#filtering only the columns with at least 1 missing value\n",
    "columns_with_miss = columns_with_miss[columns_with_miss!=0]\n",
    "#The number of columns with missing values\n",
    "print('Columns with missing values:', len(columns_with_miss))\n",
    "#sorting the columns by the number of missing values descending\n",
    "columns_with_miss.sort_values(ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop the unuseful columns: salary, salary_currency (both covered by salary_in_usd)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['salary', 'salary_currency'], inplace=True)\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform String data to Integer values\n",
    "#### First, print all column's possible values to see what we are working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data.columns:\n",
    "    if data[column].dtype != 'int64':\n",
    "        print(data[column].value_counts())\n",
    "print(data['company_location'].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Codify simple, ordinal data\n",
    "experience_level (entry, mid, senior, executive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['experience_level'].replace({\n",
    "    'EN': 1,\n",
    "    'MI': 2,\n",
    "    'SE': 3,\n",
    "    'EX': 4,\n",
    "}, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "company_size (S, M, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['company_size'].replace({\n",
    "    'S': 1,\n",
    "    'M': 2,\n",
    "    'L': 3\n",
    "}, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remote_ratio (0, 50, 100) ->  (0, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['remote_ratio'].replace({\n",
    "    0: 0,\n",
    "    50: 1,\n",
    "    100: 2\n",
    "}, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Codify non-ordinal data\n",
    "by converting a column to multiple binary value columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_column(data, column):\n",
    "    dummies = pd.get_dummies(data[column], prefix=column)\n",
    "    data = pd.concat([data, dummies], axis=1)\n",
    "    data.drop(columns=[column], inplace=True)\n",
    "    return data\n",
    "min_occurences = 50 \n",
    "def bin_values(data, column):\n",
    "    # Number of occurrences\n",
    "    counts = data[column].value_counts()\n",
    "    # Create a list with all values that have less than x occurrences\n",
    "    other_values = list(counts[counts < min_occurences].index)\n",
    "    # Replace the values in the \"other_values\" list with \"Other\"\n",
    "    data[column].replace(other_values, \"Other\", inplace=True)\n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "employment_type\n",
    "FT    2973\n",
    "PT      15\n",
    "CT       9\n",
    "FL       7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = one_hot_encode_column(data, 'employment_type')\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "job_title simplification (reduce it to 4 main job categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_job_title_to_category(job_title):\n",
    "    if \"analyst\" in job_title.lower():\n",
    "        return \"Data Analyst\"\n",
    "    elif \"machine\" in job_title.lower():\n",
    "        return \"Machine Learning Engineer\"\n",
    "    elif \"scientist\" in job_title.lower():\n",
    "        return \"Data Scientist\"\n",
    "    elif \"engineer\" in job_title.lower():\n",
    "        return \"Data Engineer\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "# Create a new column called \"job_category\" and remove old column\n",
    "data[\"job_category\"] = data[\"job_title\"].apply(map_job_title_to_category)\n",
    "data[\"job_category\"].value_counts()\n",
    "data = data.drop('job_title', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = bin_values(data, 'job_category')\n",
    "data = one_hot_encode_column(data, 'job_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "employee_residence (bin all countries with less than x value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = bin_values(data, 'employee_residence')\n",
    "data = one_hot_encode_column(data, 'employee_residence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "company_location (bin all countries with less than x value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = bin_values(data, 'company_location')\n",
    "data = one_hot_encode_column(data, 'company_location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make this notebook's output identical at every run\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# stratify by experience level since that is one of the most important attributes\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(data, data[\"experience_level\"]):\n",
    "    strat_train_set = data.loc[train_index]\n",
    "    strat_test_set = data.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check distribution of train and test\n",
    "strat_test_set[\"experience_level\"].value_counts() / len(strat_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set[\"experience_level\"].value_counts() / len(strat_train_set)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check distribution of Experience_level in different sets: Overall, Stratified, Randomized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def income_cat_proportions(data):\n",
    "    return data[\"experience_level\"].value_counts() / len(data)\n",
    "\n",
    "train_set, test_set = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "compare_props = pd.DataFrame({\n",
    "    \"Overall\": income_cat_proportions(data),\n",
    "    \"Stratified\": income_cat_proportions(strat_test_set),\n",
    "    \"Random\": income_cat_proportions(test_set),\n",
    "}).sort_index()\n",
    "compare_props[\"Rand. %error\"] = 100 * compare_props[\"Random\"] / compare_props[\"Overall\"] - 100\n",
    "compare_props[\"Strat. %error\"] = 100 * compare_props[\"Stratified\"] / compare_props[\"Overall\"] - 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cautam corelatia dintre salariu si restul atributelor\n",
    "data = strat_train_set.copy()\n",
    "corr_matrix = data.corr()\n",
    "corr_matrix[\"salary_in_usd\"].sort_values(ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
